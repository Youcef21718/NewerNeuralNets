import os
import functools
import operator
import gzip
import struct
import array
import tempfile
import numpy as np

try:
    from urllib.request import urlretrieve
except ImportError:
    from urllib import urlretrieve  # py2
try:
    from urllib.parse import urljoin
except ImportError:
    from urlparse import urljoin

# the url can be changed by the users of the library (not a constant)
datasets_url = 'http://yann.lecun.com/exdb/mnist/'


class IdxDecodeError(ValueError):
    """Raised when an invalid idx file is parsed."""
    pass


def download_file(fname, target_dir=None, force=False):
    """Download fname from the datasets_url, and save it to target_dir,
    unless the file already exists, and force is False.
    Parameters
    ----------
    fname : str
        Name of the file to download
    target_dir : str
        Directory where to store the file
    force : bool
        Force downloading the file, if it already exists
    Returns
    -------
    fname : str
        Full path of the downloaded file
    """
    if not target_dir:
        target_dir = tempfile.gettempdir()
    target_fname = os.path.join(target_dir, fname)

    if force or not os.path.isfile(target_fname):
        url = urljoin(datasets_url, fname)
        urlretrieve(url, target_fname)

    return target_fname


def parse_idx(fd):
    """Parse an IDX file, and return it as a numpy array.
    Parameters
    ----------
    fd : file
        File descriptor of the IDX file to parse
    endian : str
        Byte order of the IDX file. See [1] for available options
    Returns
    -------
    data : numpy.ndarray
        Numpy array with the dimensions and the data in the IDX file
    1. https://docs.python.org/3/library/struct.html#byte-order-size-and-alignment
    """
    DATA_TYPES = {0x08: 'B',  # unsigned byte
                  0x09: 'b',  # signed byte
                  0x0b: 'h',  # short (2 bytes)
                  0x0c: 'i',  # int (4 bytes)
                  0x0d: 'f',  # float (4 bytes)
                  0x0e: 'd'}  # double (8 bytes)

    header = fd.read(4)
    if len(header) != 4:
        raise IdxDecodeError('Invalid IDX file, file empty or does not contain a full header.')

    zeros, data_type, num_dimensions = struct.unpack('>HBB', header)

    if zeros != 0:
        raise IdxDecodeError('Invalid IDX file, file must start with two zero bytes. '
                             'Found 0x%02x' % zeros)

    try:
        data_type = DATA_TYPES[data_type]
    except KeyError:
        raise IdxDecodeError('Unknown data type 0x%02x in IDX file' % data_type)

    dimension_sizes = struct.unpack('>' + 'I' * num_dimensions,
                                    fd.read(4 * num_dimensions))

    data = array.array(data_type, fd.read())
    data.byteswap()  # looks like array.array reads data as little endian

    expected_items = functools.reduce(operator.mul, dimension_sizes)
    if len(data) != expected_items:
        raise IdxDecodeError('IDX file has wrong number of items. '
                             'Expected: %d. Found: %d' % (expected_items, len(data)))

    return np.array(data).reshape(dimension_sizes)


def download_and_parse_mnist_file(fname, target_dir=None, force=False):
    """Download the IDX file named fname from the URL specified in dataset_url
    and return it as a numpy array.
    Parameters
    ----------
    fname : str
        File name to download and parse
    target_dir : str
        Directory where to store the file
    force : bool
        Force downloading the file, if it already exists
    Returns
    -------
    data : numpy.ndarray
        Numpy array with the dimensions and the data in the IDX file
    """
    fname = download_file(fname, target_dir=target_dir, force=force)
    fopen = gzip.open if os.path.splitext(fname)[1] == '.gz' else open
    with fopen(fname, 'rb') as fd:
        return parse_idx(fd)


def train_images():
    """Return train images from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    train_images : numpy.ndarray
        Numpy array with the images in the train MNIST database. The first
        dimension indexes each sample, while the other two index rows and
        columns of the image
    """
    return download_and_parse_mnist_file('train-images-idx3-ubyte.gz')


def test_images():
    """Return test images from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    test_images : numpy.ndarray
        Numpy array with the images in the train MNIST database. The first
        dimension indexes each sample, while the other two index rows and
        columns of the image
    """
    return download_and_parse_mnist_file('t10k-images-idx3-ubyte.gz')


def train_labels():
    """Return train labels from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    train_labels : numpy.ndarray
        Numpy array with the labels 0 to 9 in the train MNIST database.
    """
    return download_and_parse_mnist_file('train-labels-idx1-ubyte.gz')


def test_labels():
    """Return test labels from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    test_labels : numpy.ndarray
        Numpy array with the labels 0 to 9 in the train MNIST database.
    """
    return download_and_parse_mnist_file('t10k-labels-idx1-ubyte.gz')

import matplotlib.pyplot as plt

from scipy.linalg import svd
from scipy.linalg import orth

def show(array, index):
    plt.imshow(array[index], cmap=plt.get_cmap('gray_r'))
    plt.show()

def sig(m):
    return (np.exp(m))/(1+np.exp(m))

def dsig(m):
    return sig(m)*(1-sig(m))

def accuracy(sL1, B23, B12, W23, W12, Y):
    L2 = sL1.dot(W12)+B12
    sL2 = sig(L2)

    L3 = sL2.dot(W23)+B23
    sL3 = sig(L3)

    labels = np.argmax(sL3, axis=1)

    return np.sum(labels == Y)

def acc(sL, Y):
    labels = np.argmax(sL, axis=1)
    return np.sum(labels == Y)

def cost(sL1, B23, B12, W23, W12, Y):
    L2 = sL1.dot(W12)+B12
    sL2 = sig(L2)

    L3 = sL2.dot(W23)+B23
    sL3 = sig(L3)

    return np.sum(0.5*(sL3-Y)*(sL3-Y))

W12 = np.random.normal(0, 1/np.sqrt(784), (784,30))
W23 = np.random.normal(0, 1/np.sqrt(30), (30,10))

W12 = orth(W12)
W23 = orth(W23)

I12 = np.identity(30)
I23 = np.identity(10)

B12 = np.random.normal(0, 1, (30))
B23 = np.random.normal(0, 1, (10))

# label
trainLabels = np.zeros((60000,10))
trainLabels[np.arange(60000), train_labels()] = 1

# input
trainImages = train_images().reshape(60000,784)/256

# hyperparameters
batch = 10
numEpochs = 30;
epochTime = 60000/batch
learningRate = 3/batch

for i in range(numEpochs):
    print(accuracy(trainImages, B23, B12, W23, W12, train_labels()))
    print(0.25*np.sum(((W12.T).dot(W12) - I12)**2))
    print(0.25*np.sum(((W23.T).dot(W23) - I23)**2))

    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = trainImages[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23 = (sL3-Y)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W23 = W23 - learningRate*dW23
        W23 = W23 - 0.01*W23.dot((W23.T).dot(W23) - I23)
        W12 = W12 - learningRate*dW12
        W12 = W12 - 0.01*W12.dot((W12.T).dot(W12) - I12)



# label
testLabels = np.zeros((10000,10))
testLabels[np.arange(10000), test_labels()] = 1

# input
testImages = test_images().reshape(10000,784)/256

accuracy(testImages, B23, B12, W23, W12, test_labels())

plt.imshow(trainImages[0].reshape(28,28),cmap=plt.get_cmap('gray_r'))

--------------------------------------------------------------------------


W12 = np.random.normal(0, 1/np.sqrt(784), (784,30))
W23 = np.random.normal(0, 1/np.sqrt(30), (30,10))

W12 = orth(W12)
W23 = orth(W23)

I12 = np.identity(30)
I23 = np.identity(10)

B12 = np.random.normal(0, 1, (30))
B23 = np.random.normal(0, 1, (10))

# label
trainLabels = np.zeros((60000,10))
trainLabels[np.arange(60000), train_labels()] = 1

# input
trainImages = train_images().reshape(60000,784)/256

# hyperparameters
batch = 10
numEpochs = 30;
epochTime = 60000/batch
learningRate = 3/batch

for i in range(numEpochs):
    print(accuracy(trainImages, B23, B12, W23, W12, train_labels()))
    print(0.25*np.sum(((W12.T).dot(W12) - I12)**2))
    print(0.25*np.sum(((W23.T).dot(W23) - I23)**2))

    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = trainImages[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23 = (sL3-Y)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W23 = W23 - learningRate*dW23
        W12 = W12 - learningRate*dW12


--------------------------------------------------------------------------

W12 = np.random.normal(0, 1/np.sqrt(784), (784,30))
W23 = np.random.normal(0, 1/np.sqrt(30), (30,10))

W12 = orth(W12)
W23 = orth(W23)

I12 = np.identity(30)
I23 = np.identity(10)

B12 = np.random.normal(0, 1, (30))
B23 = np.random.normal(0, 1, (10))

# label
trainLabels = np.zeros((60000,10))
trainLabels[np.arange(60000), train_labels()] = 1

# input
trainImages = train_images().reshape(60000,784)/256

# hyperparameters
batch = 10
numEpochs = 30;
epochTime = 60000/batch
learningRate = 0.01

for i in range(numEpochs):
    print(accuracy(trainImages, B23, B12, W23, W12, train_labels()))
    print(0.25*np.sum(((W12.T).dot(W12) - I12)**2))
    print(0.25*np.sum(((W23.T).dot(W23) - I23)**2))

    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = trainImages[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23 = (sL3-Y)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W23 = W23 - learningRate*dW23
        U, s, Vh = svd(W23, full_matrices=False)
        W23 = U.dot(Vh)

        W12 = W12 - learningRate*dW12
        U, s, Vh = svd(W12, full_matrices=False)
        W12 = U.dot(Vh)

--------------------------------------------------------------------------

W12 = np.random.normal(0, 1/np.sqrt(784), (784,30))
W23 = np.random.normal(0, 1/np.sqrt(50), (30,30))
W34 = np.random.normal(0, 1/np.sqrt(30), (30,10))

W12 = orth(W12)
W23 = orth(W23)
W34 = orth(W34)

I12 = np.identity(30)
I23 = np.identity(30)
I34 = np.identity(10)

B12 = np.random.normal(0, 1/30, (30))
B23 = np.random.normal(0, 1/30, (30))
B34 = np.random.normal(0, 1/10, (10))

# label
trainLabels = np.zeros((60000,10))
trainLabels[np.arange(60000), train_labels()] = 1

# input
trainImages = train_images().reshape(60000,784)/256

# hyperparameters
batch = 10
numEpochs = 30;
epochTime = 60000/batch
learningRate = 0.01

for i in range(numEpochs):
    sL = sig(sig(sig(trainImages.dot(W12)+B12).dot(W23)+B23).dot(W34)+B34)
    print(acc(sL, train_labels()))
    print(0.25*np.sum(((W12.T).dot(W12) - I12)**2))
    print(0.25*np.sum(((W23.T).dot(W23) - I23)**2))
    print(0.25*np.sum(((W34.T).dot(W34) - I34)**2))

    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = trainImages[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        L4 = sL3.dot(W34)+B34
        sL4 = sig(L4)

        # gradients

        dB34 = (sL4-Y)*dsig(L4)
        dB23 = dB34.dot(W34.T)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW34 = (sL3.T).dot(dB34)
        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B34 = B34 - learningRate*dB34.sum(axis=0)
        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W34 = W34 - learningRate*dW34
        U, s, Vh = svd(W34, full_matrices=False)
        W34 = U.dot(Vh)

        W23 = W23 - learningRate*dW23
        U, s, Vh = svd(W23, full_matrices=False)
        W23 = U.dot(Vh)

        W12 = W12 - learningRate*dW12
        U, s, Vh = svd(W12, full_matrices=False)
        W12 = U.dot(Vh)


--------------------------------------------------------------------------

W12 = np.random.normal(0, 1/np.sqrt(784), (784,150))
W23 = np.random.normal(0, 1/np.sqrt(100), (150,100))
W34 = np.random.normal(0, 1/np.sqrt(50), (100,10))

W12 = orth(W12)
W23 = orth(W23)
W34 = orth(W34)

I12 = np.identity(150)
I23 = np.identity(100)
I34 = np.identity(10)

B12 = np.random.normal(0, 1/150, (150))
B23 = np.random.normal(0, 1/100, (100))
B34 = np.random.normal(0, 1/10, (10))

# label
trainLabels = np.zeros((60000,10))
trainLabels[np.arange(60000), train_labels()] = 1

# input
trainImages = train_images().reshape(60000,784)/256

# hyperparameters
batch = 10
numEpochs = 30;
epochTime = 60000/batch
learningRate = 0.001

for i in range(numEpochs):
    sL = sig(sig(sig(trainImages.dot(W12)+B12).dot(W23)+B23).dot(W34)+B34)
    print(acc(sL, train_labels()))
    print(0.25*np.sum(((W12.T).dot(W12) - I12)**2))
    print(0.25*np.sum(((W23.T).dot(W23) - I23)**2))
    print(0.25*np.sum(((W34.T).dot(W34) - I34)**2))

    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = trainImages[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        L4 = sL3.dot(W34)+B34
        sL4 = sig(L4)

        # gradients

        dB34 = (sL4-Y)*dsig(L4)
        dB23 = dB34.dot(W34.T)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW34 = (sL3.T).dot(dB34)
        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B34 = B34 - learningRate*dB34.sum(axis=0)
        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W34 = W34 - learningRate*dW34
        U, s, Vh = svd(W34, full_matrices=False)
        W34 = U.dot(Vh)

        W23 = W23 - learningRate*dW23
        U, s, Vh = svd(W23, full_matrices=False)
        W23 = U.dot(Vh)

        W12 = W12 - learningRate*dW12
        U, s, Vh = svd(W12, full_matrices=False)
        W12 = U.dot(Vh)


--------------------------------------------------------------------------

W12 = np.random.normal(0, 1/np.sqrt(784), (784,150))
W23 = np.random.normal(0, 1/np.sqrt(150), (150,100))
W34 = np.random.normal(0, 1/np.sqrt(100), (100,10))

W12 = orth(W12)
W23 = orth(W23)
W34 = orth(W34)

I12 = np.identity(150)
I23 = np.identity(100)
I34 = np.identity(10)

B12 = np.random.normal(0, 1, (150))
B23 = np.random.normal(0, 1, (100))
B34 = np.random.normal(0, 1, (10))

# label
trainLabels = np.zeros((60000,10))
trainLabels[np.arange(60000), train_labels()] = 1

# input
trainImages = train_images().reshape(60000,784)/256

# hyperparameters
batch = 10
numEpochs = 30;
epochTime = 60000/batch
learningRate = 3/batch

for i in range(numEpochs):
    sL = sig(sig(sig(trainImages.dot(W12)+B12).dot(W23)+B23).dot(W34)+B34)
    print(acc(sL, train_labels()))
    print(0.25*np.sum(((W12.T).dot(W12) - I12)**2))
    print(0.25*np.sum(((W23.T).dot(W23) - I23)**2))
    print(0.25*np.sum(((W34.T).dot(W34) - I34)**2))

    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = trainImages[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        L4 = sL3.dot(W34)+B34
        sL4 = sig(L4)

        # gradients

        dB34 = (sL4-Y)*dsig(L4)
        dB23 = dB34.dot(W34.T)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW34 = (sL3.T).dot(dB34)
        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B34 = B34 - learningRate*dB34.sum(axis=0)
        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W34 = W34 - learningRate*dW34
        W34 = W34 - 0.001*W34.dot((W34.T).dot(W34) - I34)

        W23 = W23 - learningRate*dW23
        W23 = W23 - 0.001*W23.dot((W23.T).dot(W23) - I23)

        W12 = W12 - learningRate*dW12
        W12 = W12 - 0.001*W12.dot((W12.T).dot(W12) - I12)








