import os
import functools
import operator
import gzip
import struct
import array
import tempfile
import numpy as np

try:
    from urllib.request import urlretrieve
except ImportError:
    from urllib import urlretrieve  # py2
try:
    from urllib.parse import urljoin
except ImportError:
    from urlparse import urljoin

# the url can be changed by the users of the library (not a constant)
datasets_url = 'http://yann.lecun.com/exdb/mnist/'


class IdxDecodeError(ValueError):
    """Raised when an invalid idx file is parsed."""
    pass


def download_file(fname, target_dir=None, force=False):
    """Download fname from the datasets_url, and save it to target_dir,
    unless the file already exists, and force is False.
    Parameters
    ----------
    fname : str
        Name of the file to download
    target_dir : str
        Directory where to store the file
    force : bool
        Force downloading the file, if it already exists
    Returns
    -------
    fname : str
        Full path of the downloaded file
    """
    if not target_dir:
        target_dir = tempfile.gettempdir()
    target_fname = os.path.join(target_dir, fname)

    if force or not os.path.isfile(target_fname):
        url = urljoin(datasets_url, fname)
        urlretrieve(url, target_fname)

    return target_fname


def parse_idx(fd):
    """Parse an IDX file, and return it as a numpy array.
    Parameters
    ----------
    fd : file
        File descriptor of the IDX file to parse
    endian : str
        Byte order of the IDX file. See [1] for available options
    Returns
    -------
    data : numpy.ndarray
        Numpy array with the dimensions and the data in the IDX file
    1. https://docs.python.org/3/library/struct.html#byte-order-size-and-alignment
    """
    DATA_TYPES = {0x08: 'B',  # unsigned byte
                  0x09: 'b',  # signed byte
                  0x0b: 'h',  # short (2 bytes)
                  0x0c: 'i',  # int (4 bytes)
                  0x0d: 'f',  # float (4 bytes)
                  0x0e: 'd'}  # double (8 bytes)

    header = fd.read(4)
    if len(header) != 4:
        raise IdxDecodeError('Invalid IDX file, file empty or does not contain a full header.')

    zeros, data_type, num_dimensions = struct.unpack('>HBB', header)

    if zeros != 0:
        raise IdxDecodeError('Invalid IDX file, file must start with two zero bytes. '
                             'Found 0x%02x' % zeros)

    try:
        data_type = DATA_TYPES[data_type]
    except KeyError:
        raise IdxDecodeError('Unknown data type 0x%02x in IDX file' % data_type)

    dimension_sizes = struct.unpack('>' + 'I' * num_dimensions,
                                    fd.read(4 * num_dimensions))

    data = array.array(data_type, fd.read())
    data.byteswap()  # looks like array.array reads data as little endian

    expected_items = functools.reduce(operator.mul, dimension_sizes)
    if len(data) != expected_items:
        raise IdxDecodeError('IDX file has wrong number of items. '
                             'Expected: %d. Found: %d' % (expected_items, len(data)))

    return np.array(data).reshape(dimension_sizes)


def download_and_parse_mnist_file(fname, target_dir=None, force=False):
    """Download the IDX file named fname from the URL specified in dataset_url
    and return it as a numpy array.
    Parameters
    ----------
    fname : str
        File name to download and parse
    target_dir : str
        Directory where to store the file
    force : bool
        Force downloading the file, if it already exists
    Returns
    -------
    data : numpy.ndarray
        Numpy array with the dimensions and the data in the IDX file
    """
    fname = download_file(fname, target_dir=target_dir, force=force)
    fopen = gzip.open if os.path.splitext(fname)[1] == '.gz' else open
    with fopen(fname, 'rb') as fd:
        return parse_idx(fd)


def train_images():
    """Return train images from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    train_images : numpy.ndarray
        Numpy array with the images in the train MNIST database. The first
        dimension indexes each sample, while the other two index rows and
        columns of the image
    """
    return download_and_parse_mnist_file('train-images-idx3-ubyte.gz')


def test_images():
    """Return test images from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    test_images : numpy.ndarray
        Numpy array with the images in the train MNIST database. The first
        dimension indexes each sample, while the other two index rows and
        columns of the image
    """
    return download_and_parse_mnist_file('t10k-images-idx3-ubyte.gz')


def train_labels():
    """Return train labels from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    train_labels : numpy.ndarray
        Numpy array with the labels 0 to 9 in the train MNIST database.
    """
    return download_and_parse_mnist_file('train-labels-idx1-ubyte.gz')


def test_labels():
    """Return test labels from Yann LeCun MNIST database as a numpy array.
    Download the file, if not already found in the temporary directory of
    the system.
    Returns
    -------
    test_labels : numpy.ndarray
        Numpy array with the labels 0 to 9 in the train MNIST database.
    """
    return download_and_parse_mnist_file('t10k-labels-idx1-ubyte.gz')

import matplotlib.pyplot as plt

def show(array):
    plt.imshow(array.reshape(28,28),cmap=plt.get_cmap('gray_r'))
    plt.show()

def sig(m):
    return 1/(1+np.exp(-m))

def dsig(m):
    return sig(m)*(1-sig(m))

def softmax(M):
    M0 = np.exp(M)
    M1 = np.sum(M0, axis=1)
    return (M0.T/M1).T

def accuracy(sL1, B23, B12, W23, W12, Y):
    L2 = sL1.dot(W12)+B12
    sL2 = sig(L2)

    L3 = sL2.dot(W23)+B23
    sL3 = sig(L3)

    labels = np.argmax(sL3, axis=1)

    return np.sum(labels == Y)

def cost(sL1, B23, B12, W23, W12, Y):
    L2 = sL1.dot(W12)+B12
    sL2 = sig(L2)

    L3 = sL2.dot(W23)+B23
    sL3 = sig(L3)

    return np.sum(0.5*(sL3-Y)*(sL3-Y))

# label
trainLabels = np.zeros((60000,10))
trainLabels[np.arange(60000), train_labels()] = 1

# input
trainImages = train_images().reshape(60000,784)/256

# label
testLabels = np.zeros((10000,10))
testLabels[np.arange(10000), test_labels()] = 1

# input
testImages = test_images().reshape(10000,784)/256

# hyperparameters
batch = 10
numEpochs = 30;
epochTime = 60000/batch
learningRate = 0.4/batch

# train MNIST

W12 = np.random.normal(0, 1/np.sqrt(784), (784,30))
W23 = np.random.normal(0, 1/np.sqrt(30), (30,10))

B12 = np.random.normal(0, 1, (30))
B23 = np.random.normal(0, 1, (10))

for i in range(numEpochs):
    print(accuracy(trainImages, B23, B12, W23, W12, train_labels()))
    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = trainImages[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = softmax(L3)

        # gradients

        dB23 = (sL3-Y)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W23 = W23 - learningRate*dW23
        W12 = W12 - learningRate*dW12



accuracy(testImages, B23, B12, W23, W12, test_labels())
plt.imshow(trainImages[0].reshape(28,28),cmap=plt.get_cmap('gray_r'))






# Edge Weight Consolidation???

W12a = W12.copy()
W23a = W23.copy()
B12a = B12.copy()
B23a = B23.copy()

W12 = W12a.copy()
W23 = W23a.copy()
B12 = B12a.copy()
B23 = B23a.copy()

permutation = np.arange(784)
np.random.shuffle(permutation)
train = trainImages[:,permutation]

for i in range(numEpochs):
    print(accuracy(trainImages, B23a, B12a, W23a, W12a, train_labels()), accuracy(trainImages, B23, B12, W23, W12, train_labels()) , accuracy(train, B23, B12, W23, W12, train_labels()) )
    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = train[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = softmax(L3)

        # gradients

        dB23 = (sL3-Y)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # diffs
     
        print(np.sum((B23 - B23a)**2))
        B23diff = (B23 - B23a)**2
        B12diff = (B12 - B12a)**2

        W23diff = (W23 - W23a)**2
        W12diff = (W12 - W12a)**2

        # diff neural network

        L2diff = sL1.dot(W12diff)+B12diff
        sL2diff = sig(L2diff)

        L3diff = sL2diff.dot(W23diff)+B23diff
        sL3diff = sig(L3diff)

        # diff gradients

        dB23diff = (1-10*sL3diff)
        dB12diff = dB23diff.dot(W23diff.T)*dsig(L2diff)

        dW23diff = (sL2diff.T).dot(dB23diff)
        dW12diff = (sL1.T).dot(dB12diff)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0) - 0.001*dB23diff.sum(axis=0)*B23diff.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0) - 0.001*dB12diff.sum(axis=0)*B12diff.sum(axis=0)

        W23 = W23 - learningRate*dW23 - 0.001*dW23diff*W23diff
        W12 = W12 - learningRate*dW12 - 0.001*dW12diff*W12diff











































































# Catastrophic forgetting

permutation = np.arange(784)
np.random.shuffle(permutation)
train = trainImages[:,permutation]

for i in range(numEpochs):
    print(accuracy(trainImages, B23, B12, W23, W12, train_labels()) , accuracy(train, B23, B12, W23, W12, train_labels()) )
    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = train[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23 = (sL3-Y)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W23 = W23 - learningRate*dW23
        W12 = W12 - learningRate*dW12

58755 5259
54418 44385
50387 49760
48709 50207
49273 50894
47253 51176
46749 51314
45647 51432
45547 51453
44600 51725
43699 51808
42144 51940
40879 52049
40598 52158
40610 51891
39594 52163
38444 52339
37568 52105
34840 52318
35980 52319
34363 52282
34466 52416
33322 52504
34143 52508
33914 52562
32906 52563
32402 52510
31801 52565
30765 52408
30725 52609


# Catastrophic forgetting with L2 Loss

W12a = W12.copy()
W23a = W23.copy()
B12a = B12.copy()
B23a = B23.copy()

permutation = np.arange(784)
np.random.shuffle(permutation)
train = trainImages[:,permutation]

for i in range(numEpochs):
    print(accuracy(trainImages, B23a, B12a, W23a, W12a, train_labels()), accuracy(trainImages, B23, B12, W23, W12, train_labels()) , accuracy(train, B23, B12, W23, W12, train_labels()) )
    for j in range(int(epochTime)):

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = train[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23 = (sL3-Y)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W23 = W23 - learningRate*(dW23 + 0.01*(W23 - W23a))
        W12 = W12 - learningRate*(dW12 + 0.01*(W12 - W12a))

# training together

permutation = np.arange(784)
np.random.shuffle(permutation)
train2 = trainImages[:,permutation]
trains = np.concatenate((trainImages, train2))

for i in range(numEpochs):
    print(accuracy(trainImages, B23, B12, W23, W12, train_labels()) , accuracy(train2, B23, B12, W23, W12, train_labels()) )
    for j in range(int(epochTime)):

        nums = np.arange(120000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle%60000]
        sL1 = trains[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23 = (sL3-Y)*dsig(L3)
        dB12 = dB23.dot(W23.T)*dsig(L2)

        dW23 = (sL2.T).dot(dB23)
        dW12 = (sL1.T).dot(dB12)

        # update

        B23 = B23 - learningRate*dB23.sum(axis=0)
        B12 = B12 - learningRate*dB12.sum(axis=0)

        W23 = W23 - learningRate*dW23
        W12 = W12 - learningRate*dW12


# learning without forgetting (dark knowledge)

w12 = W12.copy()
w23 = W23.copy()
b12 = B12.copy()
b23 = B23.copy()

W12 = w12.copy()
W23 = w23.copy()
B12 = b12.copy()
B23 = b23.copy()

learningRate = 0.05

permutation = np.arange(784)
np.random.shuffle(permutation)
train2 = trainImages[:,permutation]
label2 = sig(sig(train2.dot(W12)+B12).dot(W23)+B23)

for i in range(numEpochs):
    print(accuracy(trainImages, B23, B12, W23, W12, train_labels()) , accuracy(train2, B23, B12, W23, W12, train_labels()) )
    for j in range(int(epochTime)):

        # ----------------------------------------

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = trainLabels[shuffle]
        sL1 = train2[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23_1 = (sL3-Y)*dsig(L3)
        dB12_1 = dB23.dot(W23.T)*dsig(L2)

        dW23_1 = (sL2.T).dot(dB23)
        dW12_1 = (sL1.T).dot(dB12)

        # ----------------------------------------

        nums = np.arange(60000)
        np.random.shuffle(nums)
        shuffle = nums[:batch]

        Y = label2[shuffle]
        sL1 = train2[shuffle]

        # neural network

        L2 = sL1.dot(W12)+B12
        sL2 = sig(L2)

        L3 = sL2.dot(W23)+B23
        sL3 = sig(L3)

        # gradients

        dB23_2 = (sL3-Y)*dsig(L3)
        dB12_2 = dB23.dot(W23.T)*dsig(L2)

        dW23_2 = (sL2.T).dot(dB23)
        dW12_2 = (sL1.T).dot(dB12)

        # ----------------------------------------

        # update

        B23 = B23 - learningRate*(dB23_1.sum(axis=0))
        B12 = B12 - learningRate*(dB12_1.sum(axis=0))

        W23 = W23 - learningRate*(dW23_1)
        W12 = W12 - learningRate*(dW12_1)



























